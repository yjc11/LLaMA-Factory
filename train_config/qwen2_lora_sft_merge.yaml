### Note: DO NOT use quantized model or quantization_bit when merging lora adapters

### model
model_name_or_path: /public/youjiachen/models/Qwen2-0.5B-Instruct
adapter_name_or_path: /public/youjiachen/workspace/LLaMA-Factory/saves/qwen2-0.5b/lora/sft/checkpoint-500
template: qwen
finetuning_type: lora

### export
export_dir: models/qwen2_lora_sft
export_size: 2
export_device: gpu
export_legacy_format: false
